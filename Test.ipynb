{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (0.1.17)\n",
      "Requirement already satisfied: neo4j in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (5.20.0)\n",
      "Requirement already satisfied: openai in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (0.28.0)\n",
      "Requirement already satisfied: wikipedia in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (1.4.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (0.1.4)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.36 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from langchain) (0.0.36)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from langchain) (0.6.5)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from langchain) (0.1.52)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from langchain) (2.7.1)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from langchain) (0.1.48)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: pytz in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from neo4j) (2024.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from wikipedia) (4.12.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from tiktoken) (2024.4.28)\n",
      "Collecting openai\n",
      "  Using cached openai-1.30.1-py3-none-any.whl (320 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from langchain-core<0.2.0,>=0.1.48->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.2)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from beautifulsoup4->wikipedia) (2.5)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\wendychuaxingzhao\\onedrive - srkk group of companies\\documents\\msds\\knowledge graph test\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.0\n",
      "    Uninstalling openai-0.28.0:\n",
      "      Successfully uninstalled openai-0.28.0\n",
      "Successfully installed openai-1.30.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install langchain neo4j openai wikipedia tiktoken langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Package Imports\n",
    "from langchain.graphs import Neo4jGraph\n",
    "import neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neo4j connection\n",
    "url = \"neo4j+s://39edf771.databases.neo4j.io\"\n",
    "username =\"neo4j\"\n",
    "password = \"31Nwe5MwJKLGHFCTtkmWQVO7R3DU1fYYvX_D63HZGEM\"\n",
    "graph = Neo4jGraph(\n",
    "    url=url,\n",
    "    username=username,\n",
    "    password=password\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.graphs.graph_document import (\n",
    "    Node as BaseNode,\n",
    "    Relationship as BaseRelationship\n",
    ")\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain.pydantic_v1 import Field, BaseModel\n",
    "\n",
    "class Property(BaseModel):\n",
    "  \"\"\"A single property consisting of key and value\"\"\"\n",
    "  key: str = Field(..., description=\"key\")\n",
    "  value: str = Field(..., description=\"value\")\n",
    "\n",
    "class Node(BaseNode):\n",
    "    properties: Optional[List[Property]] = Field(\n",
    "        None, description=\"List of node properties\")\n",
    "\n",
    "class Relationship(BaseRelationship):\n",
    "    properties: Optional[List[Property]] = Field(\n",
    "        None, description=\"List of relationship properties\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"Generate a knowledge graph with entities and relationships.\"\"\"\n",
    "    nodes: List[Node] = Field(\n",
    "        ..., description=\"List of nodes in the knowledge graph\")\n",
    "    rels: List[Relationship] = Field(\n",
    "        ..., description=\"List of relationships in the knowledge graph\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chains.openai_functions import (\n",
    "    create_openai_fn_chain,\n",
    "    create_structured_output_chain,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-\"\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "\n",
    "def get_extraction_chain(\n",
    "    allowed_nodes: Optional[List[str]] = None,\n",
    "    allowed_rels: Optional[List[str]] = None\n",
    "    ):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [(\n",
    "          \"system\",\n",
    "          f\"\"\"# Knowledge Graph Instructions for GPT-4\n",
    "## 1. Overview\n",
    "You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\n",
    "- **Nodes** represent entities and concepts. They're akin to Wikipedia nodes.\n",
    "- The aim is to achieve simplicity and clarity in the knowledge graph, making it accessible for a vast audience.\n",
    "## 2. Labeling Nodes\n",
    "- **Consistency**: Ensure you use basic or elementary types for node labels.\n",
    "  - For example, when you identify an entity representing a person, always label it as **\"person\"**. Avoid using more specific terms like \"mathematician\" or \"scientist\".\n",
    "- **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\n",
    "{'- **Allowed Node Labels:**' + \", \".join(allowed_nodes) if allowed_nodes else \"\"}\n",
    "{'- **Allowed Relationship Types**:' + \", \".join(allowed_rels) if allowed_rels else \"\"}\n",
    "## 3. Handling Numerical Data and Dates\n",
    "- Numerical data, like age or other related information, should be incorporated as attributes or properties of the respective nodes.\n",
    "- **No Separate Nodes for Dates/Numbers**: Do not create separate nodes for dates or numerical values. Always attach them as attributes or properties of nodes.\n",
    "- **Property Format**: Properties must be in a key-value format.\n",
    "- **Quotation Marks**: Never use escaped single or double quotes within property values.\n",
    "- **Naming Convention**: Use camelCase for property keys, e.g., `birthDate`.\n",
    "## 4. Coreference Resolution\n",
    "- **Maintain Entity Consistency**: When extracting entities, it's vital to ensure consistency.\n",
    "If an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"),\n",
    "always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.\n",
    "Remember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial.\n",
    "## 5. Strict Compliance\n",
    "Adhere to the rules strictly. Non-compliance will result in termination.\n",
    "          \"\"\"),\n",
    "            (\"human\", \"Use the given format to extract information from the following input: {input}\"),\n",
    "            (\"human\", \"Tip: Make sure to answer in the correct format\"),\n",
    "        ])\n",
    "    return create_structured_output_chain(KnowledgeGraph, llm, prompt, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Document' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_and_store_graph\u001b[39m(\n\u001b[1;32m----> 2\u001b[0m     document: \u001b[43mDocument\u001b[49m,\n\u001b[0;32m      3\u001b[0m     nodes:Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m      4\u001b[0m     rels:Optional[List[\u001b[38;5;28mstr\u001b[39m]]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# Extract graph data using OpenAI functions\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     extract_chain \u001b[38;5;241m=\u001b[39m get_extraction_chain(nodes, rels)\n\u001b[0;32m      7\u001b[0m     data \u001b[38;5;241m=\u001b[39m extract_chain\u001b[38;5;241m.\u001b[39minvoke(document)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfunction\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Document' is not defined"
     ]
    }
   ],
   "source": [
    "def extract_and_store_graph(\n",
    "    document: Document,\n",
    "    nodes:Optional[List[str]] = None,\n",
    "    rels:Optional[List[str]]=None) -> None:\n",
    "    # Extract graph data using OpenAI functions\n",
    "    extract_chain = get_extraction_chain(nodes, rels)\n",
    "    data = extract_chain.invoke(document)['function']\n",
    "    # Construct a graph document\n",
    "    graph_document = GraphDocument(\n",
    "      nodes = [map_to_base_node(node) for node in data.nodes],\n",
    "      relationships = [map_to_base_relationship(rel) for rel in data.rels],\n",
    "      source = document\n",
    "    )\n",
    "    # Store information into a graph\n",
    "    graph.add_graph_documents([graph_document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WikipediaLoader\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "# Read the wikipedia article\n",
    "raw_documents = WikipediaLoader(query=\"Walt Disney\").load()\n",
    "# Define chunking strategy\n",
    "text_splitter = TokenTextSplitter(chunk_size=2048, chunk_overlap=24)\n",
    "\n",
    "# Only take the first the raw_documents\n",
    "documents = text_splitter.split_documents(raw_documents[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for i, d in tqdm(enumerate(documents), total=len(documents)):\n",
    "    extract_and_store_graph(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which node labels should be extracted by the LLM\n",
    "allowed_nodes = [\"Person\", \"Company\", \"Location\", \"Event\", \"Movie\", \"Service\", \"Award\"]\n",
    "\n",
    "for i, d in tqdm(enumerate(documents), total=len(documents)):\n",
    "    extract_and_store_graph(d, allowed_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the knowledge graph in a RAG application\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "\n",
    "graph.refresh_schema()\n",
    "\n",
    "cypher_chain = GraphCypherQAChain.from_llm(\n",
    "    graph=graph,\n",
    "    cypher_llm=ChatOpenAI(temperature=0, model=\"gpt-4\"),\n",
    "    qa_llm=ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\"),\n",
    "    validate_cypher=True, # Validate relationship directions\n",
    "    verbose=True\n",
    ")\n",
    "cypher_chain.run(\"When was Walter Elias Disney born?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
